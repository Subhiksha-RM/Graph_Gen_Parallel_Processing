{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiement 1 - Parallel Processing using Dask alone\n",
    "\n",
    "1. Graph Building\n",
    "\n",
    "2. Querying\n",
    "\n",
    "3. Subgraph Visualization\n",
    "\n",
    "4. Updation, Deletion and Creation of Node Atrributes, Edge Attributes, Nodes and Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dask[complete] graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-5.24.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting tenacity>=6.2.0 (from plotly)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: packaging in ./graphgen/lib/python3.12/site-packages (from plotly) (24.1)\n",
      "Downloading plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.24.1 tenacity-9.0.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dask.dataframe as dd\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('levels1mill.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from typing import Dict, List, Set, Tuple\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "class LevelBasedGraph:\n",
    "    def __init__(self):\n",
    "        self.G = nx.DiGraph()\n",
    "        self.level_index = defaultdict(set)  # Quick access to nodes by level\n",
    "        self.node_level_map = {}  # Quick lookup for node levels\n",
    "        self._lock = mp.Lock()\n",
    "        \n",
    "    def bulk_create_from_df(self, df: pd.DataFrame, num_workers: int = mp.cpu_count()):\n",
    "        \"\"\"Parallel graph construction using level-based partitioning\"\"\"\n",
    "        # Group data by level\n",
    "        level_groups = dict(tuple(df.groupby('levelno')))\n",
    "        \n",
    "        # Create level-specific subgraphs in parallel\n",
    "        with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "            futures = []\n",
    "            for level, level_df in level_groups.items():\n",
    "                futures.append(\n",
    "                    executor.submit(self._create_level_subgraph, level_df)\n",
    "                )\n",
    "            \n",
    "            # Combine results\n",
    "            for future in futures:\n",
    "                subgraph, level_nodes = future.result()\n",
    "                with self._lock:\n",
    "                    self.G.update(subgraph)\n",
    "                    level = level_nodes[0][1]  # Get level from first node\n",
    "                    self.level_index[level].update(n[0] for n in level_nodes)\n",
    "                    self.node_level_map.update(dict(level_nodes))\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_level_subgraph(df: pd.DataFrame) -> Tuple[nx.DiGraph, List[Tuple]]:\n",
    "        \"\"\"Create a subgraph for a specific level\"\"\"\n",
    "        subG = nx.DiGraph()\n",
    "        \n",
    "        # Prepare node and edge data\n",
    "        nodes_data = [(row['nodeid'], row['levelno']) for _, row in df.iterrows()]\n",
    "        edges_data = [(row['nodeid'], row['foreignkey']) for _, row in df.iterrows()]\n",
    "        \n",
    "        # Add nodes with attributes\n",
    "        node_attrs = {\n",
    "            row['nodeid']: {\n",
    "                'node_type': row['node_type'],\n",
    "                'node_weight': row['node_weight'],\n",
    "                'node_expiry': row['node_expiry']\n",
    "            }\n",
    "            for _, row in df.iterrows()\n",
    "        }\n",
    "        \n",
    "        # Add edges with attributes\n",
    "        edge_attrs = {\n",
    "            (row['nodeid'], row['foreignkey']): {\n",
    "                'edge_cost': row['edge_cost'],\n",
    "                'edge_number': row['edge_number'],\n",
    "                'time_stamp': row['time_stamp']\n",
    "            }\n",
    "            for _, row in df.iterrows()\n",
    "        }\n",
    "        \n",
    "        subG.add_nodes_from(n[0] for n in nodes_data)\n",
    "        nx.set_node_attributes(subG, node_attrs)\n",
    "        subG.add_edges_from(edges_data)\n",
    "        nx.set_edge_attributes(subG, edge_attrs)\n",
    "        \n",
    "        return subG, nodes_data\n",
    "\n",
    "    def get_subgraph_by_node(self, node_id: str, levels_up: int = 1, levels_down: int = 1) -> nx.DiGraph:\n",
    "        \"\"\"Efficiently extract subgraph around a node using level-based traversal\"\"\"\n",
    "        if node_id not in self.node_level_map:\n",
    "            return nx.DiGraph()\n",
    "            \n",
    "        current_level = self.node_level_map[node_id]\n",
    "        relevant_levels = range(\n",
    "            max(1, current_level - levels_up),\n",
    "            min(max(self.level_index.keys()) + 1, current_level + levels_down + 1)\n",
    "        )\n",
    "        \n",
    "        # Get nodes in relevant levels that are connected to our target node\n",
    "        nodes_to_check = {node_id}\n",
    "        for level in relevant_levels:\n",
    "            level_nodes = self.level_index[level]\n",
    "            connected_nodes = set()\n",
    "            \n",
    "            for node in nodes_to_check:\n",
    "                # Get predecessors and successors in the current level\n",
    "                predecessors = set(self.G.predecessors(node)) & level_nodes\n",
    "                successors = set(self.G.successors(node)) & level_nodes\n",
    "                connected_nodes.update(predecessors | successors)\n",
    "            \n",
    "            nodes_to_check.update(connected_nodes)\n",
    "        \n",
    "        # Extract the subgraph\n",
    "        return self.G.subgraph(nodes_to_check).copy()\n",
    "\n",
    "    # def parallel_update_attributes(self, updates: List[Tuple[str, Dict]], attr_type: str = 'node'):\n",
    "    #     \"\"\"Parallel attribute updates for nodes or edges\"\"\"\n",
    "    #     def update_chunk(chunk):\n",
    "    #         with self._lock:\n",
    "    #             if attr_type == 'node':\n",
    "    #                 nx.set_node_attributes(self.G, dict(chunk))\n",
    "    #             else:\n",
    "    #                 nx.set_edge_attributes(self.G, dict(chunk))\n",
    "        \n",
    "    #     # Split updates into chunks for parallel processing\n",
    "    #     chunk_size = len(updates) // mp.cpu_count()\n",
    "    #     chunks = [updates[i:i + chunk_size] for i in range(0, len(updates), chunk_size)]\n",
    "        \n",
    "    #     with ProcessPoolExecutor() as executor:\n",
    "    #         executor.map(update_chunk, chunks)\n",
    "\n",
    "    # def delete_nodes_and_update(self, nodes_to_delete: Set[str]):\n",
    "    #     \"\"\"Efficiently delete nodes and update indexes\"\"\"\n",
    "    #     with self._lock:\n",
    "    #         # Update level index\n",
    "    #         for level, nodes in self.level_index.items():\n",
    "    #             self.level_index[level] = nodes - nodes_to_delete\n",
    "            \n",
    "    #         # Update node level map\n",
    "    #         for node in nodes_to_delete:\n",
    "    #             self.node_level_map.pop(node, None)\n",
    "            \n",
    "    #         # Remove from main graph\n",
    "    #         self.G.remove_nodes_from(nodes_to_delete)\n",
    "\n",
    "# Usage example\n",
    "def create_and_query_graph(csv_file: str):\n",
    "    # Read CSV\n",
    "    df = pd.read_csv(\"levels1mill.csv\")\n",
    "    \n",
    "    # Create graph\n",
    "    graph = LevelBasedGraph()\n",
    "    graph.bulk_create_from_df(df)\n",
    "    \n",
    "    # Get subgraph example\n",
    "    subgraph = graph.get_subgraph_by_node('versyskiyo', levels_up=1, levels_down=2)\n",
    "    print(subgraph)\n",
    "    \n",
    "    return graph, subgraph\n",
    "\n",
    "# # Example parallel attribute update\n",
    "# def update_node_attributes(graph: LevelBasedGraph, updates: List[Tuple[str, Dict]]):\n",
    "#     graph.parallel_update_attributes(updates, attr_type='node')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph creation time: 31.79 seconds\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 298. GiB for an array with shape (200009, 200009) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 278\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParallel operations time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 278\u001b[0m     \u001b[43mdemo_usage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 260\u001b[0m, in \u001b[0;36mdemo_usage\u001b[0;34m()\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Example: Visualize subgraph\u001b[39;00m\n\u001b[1;32m    259\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 260\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualize_subgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mversyskiyo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisualization time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Save or display the visualization\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 147\u001b[0m, in \u001b[0;36mPregelGraphProcessor.visualize_subgraph\u001b[0;34m(self, center_node, levels_up, levels_down)\u001b[0m\n\u001b[1;32m    144\u001b[0m subgraph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_subgraph_by_node(center_node, levels_up, levels_down)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Create layout using Kamada-Kawai algorithm for better visualization\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkamada_kawai_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Prepare node traces with different colors for different levels\u001b[39;00m\n\u001b[1;32m    150\u001b[0m node_traces \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/LAM_SRM/Graph_Generator/graphgen/lib/python3.12/site-packages/networkx/drawing/layout.py:691\u001b[0m, in \u001b[0;36mkamada_kawai_layout\u001b[0;34m(G, dist, pos, weight, scale, center, dim)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dist \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    690\u001b[0m     dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(nx\u001b[38;5;241m.\u001b[39mshortest_path_length(G, weight\u001b[38;5;241m=\u001b[39mweight))\n\u001b[0;32m--> 691\u001b[0m dist_mtx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e6\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnNodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnNodes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row, nr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(G):\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nr \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dist:\n",
      "File \u001b[0;32m~/LAM_SRM/Graph_Generator/graphgen/lib/python3.12/site-packages/numpy/_core/numeric.py:206\u001b[0m, in \u001b[0;36mones\u001b[0;34m(shape, dtype, order, device, like)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m like \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ones_with_like(\n\u001b[1;32m    203\u001b[0m         like, shape, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder, device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m    204\u001b[0m     )\n\u001b[0;32m--> 206\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m multiarray\u001b[38;5;241m.\u001b[39mcopyto(a, \u001b[38;5;241m1\u001b[39m, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 298. GiB for an array with shape (200009, 200009) and data type float64"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from typing import Dict, List, Set, Tuple, Any\n",
    "from collections import defaultdict, deque\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "import time\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    source: str\n",
    "    target: str\n",
    "    data: Any\n",
    "\n",
    "class PregelGraphProcessor:\n",
    "    def __init__(self):\n",
    "        self.G = nx.DiGraph()\n",
    "        self.level_index = defaultdict(set)\n",
    "        self.node_level_map = {}\n",
    "        self.message_queues = defaultdict(deque)\n",
    "        self.visualization_queue = mp.Queue()\n",
    "        self._lock = mp.Lock()\n",
    "\n",
    "    def bulk_create_from_df(self, df: pd.DataFrame, num_workers: int = mp.cpu_count()):\n",
    "        \"\"\"Parallel graph construction using level-based partitioning\"\"\"\n",
    "        # Group data by level\n",
    "        level_groups = dict(tuple(df.groupby('levelno')))\n",
    "        \n",
    "        # Create level-specific subgraphs in parallel\n",
    "        with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "            futures = []\n",
    "            for level, level_df in level_groups.items():\n",
    "                futures.append(\n",
    "                    executor.submit(self._create_level_subgraph, level_df)\n",
    "                )\n",
    "            \n",
    "            # Combine results\n",
    "            for future in futures:\n",
    "                subgraph, level_nodes = future.result()\n",
    "                with self._lock:\n",
    "                    self.G.update(subgraph)\n",
    "                    level = level_nodes[0][1]  # Get level from first node\n",
    "                    self.level_index[level].update(n[0] for n in level_nodes)\n",
    "                    self.node_level_map.update(dict(level_nodes))\n",
    "    @staticmethod\n",
    "    def _create_level_subgraph(df: pd.DataFrame) -> Tuple[nx.DiGraph, List[Tuple]]:\n",
    "        \"\"\"Create a subgraph for a specific level\"\"\"\n",
    "        subG = nx.DiGraph()\n",
    "        \n",
    "        # Prepare node and edge data\n",
    "        nodes_data = [(row['nodeid'], row['levelno']) for _, row in df.iterrows()]\n",
    "        edges_data = [(row['nodeid'], row['foreignkey']) for _, row in df.iterrows()]\n",
    "        \n",
    "        # Add nodes with attributes\n",
    "        node_attrs = {\n",
    "            row['nodeid']: {\n",
    "                'node_type': row['node_type'],\n",
    "                'node_weight': row['node_weight'],\n",
    "                'node_expiry': row['node_expiry']\n",
    "            }\n",
    "            for _, row in df.iterrows()\n",
    "        }\n",
    "        \n",
    "        # Add edges with attributes\n",
    "        edge_attrs = {\n",
    "            (row['nodeid'], row['foreignkey']): {\n",
    "                'edge_cost': row['edge_cost'],\n",
    "                'edge_number': row['edge_number'],\n",
    "                'time_stamp': row['time_stamp']\n",
    "            }\n",
    "            for _, row in df.iterrows()\n",
    "        }\n",
    "        \n",
    "        subG.add_nodes_from(n[0] for n in nodes_data)\n",
    "        nx.set_node_attributes(subG, node_attrs)\n",
    "        subG.add_edges_from(edges_data)\n",
    "        nx.set_edge_attributes(subG, edge_attrs)\n",
    "        \n",
    "        return subG, nodes_data\n",
    "    \n",
    "    def get_subgraph_by_node(self, node_id: str, levels_up: int = 1, levels_down: int = 1) -> nx.DiGraph:\n",
    "        \"\"\"Efficiently extract subgraph around a node using level-based traversal\"\"\"\n",
    "        if node_id not in self.node_level_map:\n",
    "            return nx.DiGraph()\n",
    "            \n",
    "        current_level = self.node_level_map[node_id]\n",
    "        relevant_levels = range(\n",
    "            max(1, current_level - levels_up),\n",
    "            min(max(self.level_index.keys()) + 1, current_level + levels_down + 1)\n",
    "        )\n",
    "        \n",
    "        # Get nodes in relevant levels that are connected to our target node\n",
    "        nodes_to_check = {node_id}\n",
    "        for level in relevant_levels:\n",
    "            level_nodes = self.level_index[level]\n",
    "            connected_nodes = set()\n",
    "            \n",
    "            for node in nodes_to_check:\n",
    "                # Get predecessors and successors in the current level\n",
    "                predecessors = set(self.G.predecessors(node)) & level_nodes\n",
    "                successors = set(self.G.successors(node)) & level_nodes\n",
    "                connected_nodes.update(predecessors | successors)\n",
    "            \n",
    "            nodes_to_check.update(connected_nodes)\n",
    "        \n",
    "        # Extract the subgraph\n",
    "        return self.G.subgraph(nodes_to_check).copy()\n",
    "\n",
    "        \n",
    "    def process_messages(self, vertex: str, messages: List[Message]) -> List[Message]:\n",
    "        \"\"\"Process messages for a vertex in Pregel style\"\"\"\n",
    "        with self._lock:\n",
    "            vertex_data = self.G.nodes[vertex]\n",
    "            level = self.node_level_map[vertex]\n",
    "            \n",
    "            # Process incoming messages and generate outgoing messages\n",
    "            outgoing_messages = []\n",
    "            for msg in messages:\n",
    "                if msg.data['type'] == 'update':\n",
    "                    # Update vertex attributes\n",
    "                    self.G.nodes[vertex].update(msg.data['attributes'])\n",
    "                elif msg.data['type'] == 'delete':\n",
    "                    # Mark for deletion\n",
    "                    self.level_index[level].remove(vertex)\n",
    "                    neighbors = list(self.G.predecessors(vertex)) + list(self.G.successors(vertex))\n",
    "                    self.G.remove_node(vertex)\n",
    "                    # Notify neighbors\n",
    "                    for neighbor in neighbors:\n",
    "                        outgoing_messages.append(Message(\n",
    "                            source=vertex,\n",
    "                            target=neighbor,\n",
    "                            data={'type': 'neighbor_deleted'}\n",
    "                        ))\n",
    "            \n",
    "            return outgoing_messages\n",
    "\n",
    "    def visualize_subgraph(self, center_node: str, levels_up: int = 1, levels_down: int = 1) -> go.Figure:\n",
    "        \"\"\"Create interactive visualization of subgraph using Plotly\"\"\"\n",
    "        subgraph = self.get_subgraph_by_node(center_node, levels_up, levels_down)\n",
    "        \n",
    "        # Create layout using Kamada-Kawai algorithm for better visualization\n",
    "        pos = nx.kamada_kawai_layout(subgraph)\n",
    "        \n",
    "        # Prepare node traces with different colors for different levels\n",
    "        node_traces = []\n",
    "        edge_traces = []\n",
    "        \n",
    "        # Create color map for levels\n",
    "        unique_levels = set(self.node_level_map[n] for n in subgraph.nodes())\n",
    "        color_map = plt.cm.get_cmap('viridis')(np.linspace(0, 1, len(unique_levels)))\n",
    "        level_colors = dict(zip(unique_levels, color_map))\n",
    "        \n",
    "        # Create nodes\n",
    "        for node in subgraph.nodes():\n",
    "            level = self.node_level_map[node]\n",
    "            color = f'rgb({\",\".join(map(str, level_colors[level][:3]*255))})'\n",
    "            \n",
    "            node_trace = go.Scatter(\n",
    "                x=[pos[node][0]],\n",
    "                y=[pos[node][1]],\n",
    "                mode='markers+text',\n",
    "                name=f'Level {level}',\n",
    "                marker=dict(\n",
    "                    size=20,\n",
    "                    color=color,\n",
    "                    line=dict(width=2)\n",
    "                ),\n",
    "                text=[node],\n",
    "                hoverinfo='text',\n",
    "                showlegend=False\n",
    "            )\n",
    "            node_traces.append(node_trace)\n",
    "        \n",
    "        # Create edges\n",
    "        edge_x = []\n",
    "        edge_y = []\n",
    "        for edge in subgraph.edges():\n",
    "            x0, y0 = pos[edge[0]]\n",
    "            x1, y1 = pos[edge[1]]\n",
    "            edge_x.extend([x0, x1, None])\n",
    "            edge_y.extend([y0, y1, None])\n",
    "            \n",
    "        edge_trace = go.Scatter(\n",
    "            x=edge_x,\n",
    "            y=edge_y,\n",
    "            mode='lines',\n",
    "            line=dict(width=1, color='#888'),\n",
    "            hoverinfo='none',\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        # Create figure\n",
    "        fig = go.Figure(data=[edge_trace] + node_traces,\n",
    "                     layout=go.Layout(\n",
    "                         showlegend=False,\n",
    "                         hovermode='closest',\n",
    "                         margin=dict(b=20,l=5,r=5,t=40),\n",
    "                         xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                         yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                         title=f'Subgraph centered on {center_node}'\n",
    "                     ))\n",
    "        \n",
    "        return fig\n",
    "\n",
    "    def run_parallel_operations(self, operations: List[Dict]):\n",
    "        \"\"\"Run parallel operations using Pregel-like processing\"\"\"\n",
    "        with ProcessPoolExecutor() as executor:\n",
    "            futures = []\n",
    "            for op in operations:\n",
    "                if op['type'] == 'update':\n",
    "                    futures.append(executor.submit(\n",
    "                        self.send_message,\n",
    "                        op['target'],\n",
    "                        Message(source='system', target=op['target'], data=op)\n",
    "                    ))\n",
    "                elif op['type'] == 'delete':\n",
    "                    futures.append(executor.submit(\n",
    "                        self.process_deletion,\n",
    "                        op['target']\n",
    "                    ))\n",
    "            \n",
    "            # Wait for all operations to complete\n",
    "            for future in futures:\n",
    "                future.result()\n",
    "\n",
    "    def process_deletion(self, node: str):\n",
    "        \"\"\"Process node deletion with cascading updates\"\"\"\n",
    "        with self._lock:\n",
    "            if node in self.G:\n",
    "                level = self.node_level_map[node]\n",
    "                # Get affected subgraph\n",
    "                subgraph = self.extract_subgraph(node, levels_up=1, levels_down=1)\n",
    "                # Remove node and update indexes\n",
    "                self.level_index[level].remove(node)\n",
    "                del self.node_level_map[node]\n",
    "                self.G.remove_node(node)\n",
    "                # Visualize affected subgraph\n",
    "                self.visualize_subgraph(list(subgraph.nodes())[0] if subgraph.nodes() else None)\n",
    "\n",
    "def demo_usage():\n",
    "    \"\"\"Demonstrate usage of the enhanced graph processor\"\"\"\n",
    "    # Initialize processor\n",
    "    processor = PregelGraphProcessor()\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv('levels1mill.csv')\n",
    "    \n",
    "    # Create initial graph\n",
    "    start_time = time.time()\n",
    "    processor.bulk_create_from_df(df)\n",
    "    print(f\"Graph creation time: {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    # Example: Visualize subgraph\n",
    "    start_time = time.time()\n",
    "    fig = processor.visualize_subgraph('versyskiyo')\n",
    "    print(f\"Visualization time: {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    # Save or display the visualization\n",
    "    fig.write_html(\"subgraph_visualization.html\")\n",
    "    \n",
    "    # Example: Run parallel operations\n",
    "    operations = [\n",
    "        {'type': 'update', 'target': 'node1', 'attributes': {'weight': 1.5}},\n",
    "        {'type': 'delete', 'target': 'node2'},\n",
    "        # Add more operations as needed\n",
    "    ]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    processor.run_parallel_operations(operations)\n",
    "    print(f\"Parallel operations time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial memory usage: 7104.22 MB\n",
      "Graph creation time: 37.44s\n",
      "Memory usage after graph creation: 2471.36 MB\n",
      "Subgraph extraction time: 0.22s\n",
      "Subgraph size: 1000 nodes\n",
      "Layout calculation time: 2.84s\n",
      "Total visualization time: 3.12s\n",
      "Visualization time: 3.12s\n",
      "Final memory usage: 2487.48 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14231/1082552093.py:76: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colors = plt.cm.get_cmap('viridis')(np.linspace(0, 1, len(unique_levels)))\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from typing import Dict, Set, Optional\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "class MemoryEfficientVisualizer:\n",
    "    def __init__(self):\n",
    "        self.G = nx.DiGraph()\n",
    "        self.level_index = defaultdict(set)\n",
    "        self.node_level_map = {}\n",
    "        self.layout_cache = {}\n",
    "        \n",
    "    def extract_bounded_subgraph(self, center_node: str, max_nodes: int = 1000) -> nx.DiGraph:\n",
    "        \"\"\"Extract a bounded subgraph using BFS with node limit\"\"\"\n",
    "        if center_node not in self.G:\n",
    "            return nx.DiGraph()\n",
    "            \n",
    "        subgraph_nodes = {center_node}\n",
    "        queue = [(center_node, 0)]\n",
    "        current_level = self.node_level_map[center_node]\n",
    "        level_range = 1\n",
    "        \n",
    "        while queue and len(subgraph_nodes) < max_nodes:\n",
    "            node, depth = queue.pop(0)\n",
    "            \n",
    "            # Get neighbors within level range\n",
    "            neighbors = set()\n",
    "            for neighbor in self.G.predecessors(node):\n",
    "                if self.node_level_map[neighbor] >= current_level - level_range:\n",
    "                    neighbors.add(neighbor)\n",
    "            for neighbor in self.G.successors(node):\n",
    "                if self.node_level_map[neighbor] <= current_level + level_range:\n",
    "                    neighbors.add(neighbor)\n",
    "            \n",
    "            # Add neighbors to subgraph\n",
    "            for neighbor in neighbors:\n",
    "                if neighbor not in subgraph_nodes and len(subgraph_nodes) < max_nodes:\n",
    "                    subgraph_nodes.add(neighbor)\n",
    "                    queue.append((neighbor, depth + 1))\n",
    "        \n",
    "        return self.G.subgraph(subgraph_nodes).copy()\n",
    "\n",
    "    def calculate_efficient_layout(self, subgraph: nx.DiGraph) -> Dict:\n",
    "        \"\"\"Calculate layout using a memory-efficient approach\"\"\"\n",
    "        # Use spring_layout with optimized parameters for large graphs\n",
    "        pos = nx.spring_layout(\n",
    "            subgraph,\n",
    "            k=1/np.sqrt(len(subgraph)),  # Optimal distance between nodes\n",
    "            iterations=50,  # Reduce iterations for speed\n",
    "            seed=42  # For consistency\n",
    "        )\n",
    "        return pos\n",
    "\n",
    "    def create_interactive_visualization(self, center_node: str, max_nodes: int = 1000) -> go.Figure:\n",
    "        \"\"\"Create memory-efficient interactive visualization\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Extract bounded subgraph\n",
    "        subgraph = self.extract_bounded_subgraph(center_node, max_nodes)\n",
    "        print(f\"Subgraph extraction time: {time.time() - start_time:.2f}s\")\n",
    "        print(f\"Subgraph size: {len(subgraph)} nodes\")\n",
    "        \n",
    "        # Calculate layout\n",
    "        layout_time = time.time()\n",
    "        pos = self.calculate_efficient_layout(subgraph)\n",
    "        print(f\"Layout calculation time: {time.time() - layout_time:.2f}s\")\n",
    "        \n",
    "        # Prepare visualization data\n",
    "        node_traces = []\n",
    "        \n",
    "        # Create color map for levels\n",
    "        unique_levels = set(self.node_level_map[n] for n in subgraph.nodes())\n",
    "        colors = plt.cm.get_cmap('viridis')(np.linspace(0, 1, len(unique_levels)))\n",
    "        level_colors = dict(zip(unique_levels, colors))\n",
    "        \n",
    "        # Create edges (batch processing)\n",
    "        edge_x = []\n",
    "        edge_y = []\n",
    "        for edge in subgraph.edges():\n",
    "            x0, y0 = pos[edge[0]]\n",
    "            x1, y1 = pos[edge[1]]\n",
    "            edge_x.extend([x0, x1, None])\n",
    "            edge_y.extend([y0, y1, None])\n",
    "        \n",
    "        edge_trace = go.Scatter(\n",
    "            x=edge_x,\n",
    "            y=edge_y,\n",
    "            mode='lines',\n",
    "            line=dict(width=0.5, color='#888'),\n",
    "            hoverinfo='none'\n",
    "        )\n",
    "        \n",
    "        # Create nodes (batch processing)\n",
    "        for level in unique_levels:\n",
    "            level_nodes = [n for n in subgraph.nodes() if self.node_level_map[n] == level]\n",
    "            if not level_nodes:\n",
    "                continue\n",
    "                \n",
    "            node_x = [pos[node][0] for node in level_nodes]\n",
    "            node_y = [pos[node][1] for node in level_nodes]\n",
    "            \n",
    "            node_trace = go.Scatter(\n",
    "                x=node_x,\n",
    "                y=node_y,\n",
    "                mode='markers+text',\n",
    "                name=f'Level {level}',\n",
    "                marker=dict(\n",
    "                    size=10,\n",
    "                    color=f'rgb({\",\".join(map(str, level_colors[level][:3]*255))})',\n",
    "                    line=dict(width=1)\n",
    "                ),\n",
    "                text=level_nodes,\n",
    "                textposition=\"top center\",\n",
    "                hoverinfo='text'\n",
    "            )\n",
    "            node_traces.append(node_trace)\n",
    "        \n",
    "        # Create figure with minimal layout options\n",
    "        fig = go.Figure(\n",
    "            data=[edge_trace] + node_traces,\n",
    "            layout=go.Layout(\n",
    "                showlegend=False,\n",
    "                margin=dict(b=20,l=5,r=5,t=40),\n",
    "                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                title=f'Subgraph centered on {center_node} (showing {len(subgraph)} nodes)'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        print(f\"Total visualization time: {time.time() - start_time:.2f}s\")\n",
    "        return fig\n",
    "\n",
    "    def bulk_create_from_df(self, df: pd.DataFrame):\n",
    "        \"\"\"Efficiently create graph from DataFrame\"\"\"\n",
    "        # Create nodes and edges in bulk\n",
    "        nodes = df['nodeid'].unique()\n",
    "        edges = df[['nodeid', 'foreignkey']].values\n",
    "        \n",
    "        # Add nodes and edges to graph\n",
    "        self.G.add_nodes_from(nodes)\n",
    "        self.G.add_edges_from(edges)\n",
    "        \n",
    "        # Build level index\n",
    "        for _, row in df.iterrows():\n",
    "            node_id = row['nodeid']\n",
    "            level = row['levelno']\n",
    "            self.level_index[level].add(node_id)\n",
    "            self.node_level_map[node_id] = level\n",
    "\n",
    "def demo_usage():\n",
    "    \"\"\"Demonstrate usage with memory monitoring\"\"\"\n",
    "    import psutil\n",
    "    process = psutil.Process()\n",
    "    \n",
    "    # Initialize visualizer\n",
    "    visualizer = MemoryEfficientVisualizer()\n",
    "    \n",
    "    # Load data\n",
    "    print(f\"Initial memory usage: {process.memory_info().rss / 1024 / 1024:.2f} MB\")\n",
    "    df = pd.read_csv('levels1mill.csv')\n",
    "    \n",
    "    # Create graph\n",
    "    start_time = time.time()\n",
    "    visualizer.bulk_create_from_df(df)\n",
    "    print(f\"Graph creation time: {time.time() - start_time:.2f}s\")\n",
    "    print(f\"Memory usage after graph creation: {process.memory_info().rss / 1024 / 1024:.2f} MB\")\n",
    "    \n",
    "    # Create visualization\n",
    "    start_time = time.time()\n",
    "    fig = visualizer.create_interactive_visualization('versyskiyo', max_nodes=1000)\n",
    "    print(f\"Visualization time: {time.time() - start_time:.2f}s\")\n",
    "    print(f\"Final memory usage: {process.memory_info().rss / 1024 / 1024:.2f} MB\")\n",
    "    \n",
    "    # Save visualization\n",
    "    fig.write_html(\"memory_efficient_visualization.html\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1700013 rows of data\n",
      "Graph creation time: 55.47s\n",
      "Subgraph extraction time: 0.06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14231/3468505504.py:60: MatplotlibDeprecationWarning:\n",
      "\n",
      "The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total visualization time: 163.33s\n",
      "Visualization saved to 'interactive_visualization10k.html'\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from typing import Dict, Set, Optional\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import json\n",
    "\n",
    "class AttributeVisualizer:\n",
    "    def __init__(self):\n",
    "        self.G = nx.DiGraph()\n",
    "        self.level_index = defaultdict(set)\n",
    "        self.node_level_map = {}\n",
    "        \n",
    "    def bulk_create_from_df(self, df: pd.DataFrame):\n",
    "        \"\"\"Create graph with all attributes from DataFrame\"\"\"\n",
    "        # Create nodes with attributes\n",
    "        for _, row in df.iterrows():\n",
    "            node_id = row['nodeid']\n",
    "            self.G.add_node(\n",
    "                node_id,\n",
    "                level=row['levelno'],\n",
    "                node_type=row['node_type'],\n",
    "                node_weight=row['node_weight'],\n",
    "                node_expiry=row['node_expiry']\n",
    "            )\n",
    "            self.level_index[row['levelno']].add(node_id)\n",
    "            self.node_level_map[node_id] = row['levelno']\n",
    "            \n",
    "            # Add edge with attributes if foreignkey exists\n",
    "            if pd.notna(row['foreignkey']):\n",
    "                self.G.add_edge(\n",
    "                    node_id,\n",
    "                    row['foreignkey'],\n",
    "                    edge_cost=row['edge_cost'],\n",
    "                    edge_number=row['edge_number'],\n",
    "                    time_stamp=row['time_stamp']\n",
    "                )\n",
    "\n",
    "    def create_interactive_visualization(self, center_node: str, max_nodes: int = 1000) -> go.Figure:\n",
    "        \"\"\"Create visualization with detailed hover information\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Extract bounded subgraph\n",
    "        subgraph = self.extract_bounded_subgraph(center_node, max_nodes)\n",
    "        print(f\"Subgraph extraction time: {time.time() - start_time:.2f}s\")\n",
    "        \n",
    "        # Calculate layout\n",
    "        pos = nx.spring_layout(\n",
    "            subgraph,\n",
    "            k=1/np.sqrt(len(subgraph)),\n",
    "            iterations=50,\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "        # Prepare node traces with hover information\n",
    "        node_traces = []\n",
    "        unique_levels = set(self.node_level_map[n] for n in subgraph.nodes())\n",
    "        colors = plt.cm.get_cmap('viridis')(np.linspace(0, 1, len(unique_levels)))\n",
    "        level_colors = dict(zip(unique_levels, colors))\n",
    "        \n",
    "        # Create node traces by level with hover text\n",
    "        for level in unique_levels:\n",
    "            level_nodes = [n for n in subgraph.nodes() if self.node_level_map[n] == level]\n",
    "            if not level_nodes:\n",
    "                continue\n",
    "                \n",
    "            node_x = []\n",
    "            node_y = []\n",
    "            hover_texts = []\n",
    "            \n",
    "            for node in level_nodes:\n",
    "                node_x.append(pos[node][0])\n",
    "                node_y.append(pos[node][1])\n",
    "                \n",
    "                # Create detailed hover text with all node attributes\n",
    "                attrs = subgraph.nodes[node]\n",
    "                hover_text = f\"\"\"\n",
    "                Node ID: {node}\n",
    "                Level: {attrs.get('level', 'N/A')}\n",
    "                Type: {attrs.get('node_type', 'N/A')}\n",
    "                Weight: {attrs.get('node_weight', 'N/A')}\n",
    "                Expiry: {attrs.get('node_expiry', 'N/A')}\n",
    "                \"\"\"\n",
    "                hover_texts.append(hover_text)\n",
    "            \n",
    "            node_trace = go.Scatter(\n",
    "                x=node_x,\n",
    "                y=node_y,\n",
    "                mode='markers+text',\n",
    "                name=f'Level {level}',\n",
    "                marker=dict(\n",
    "                    size=15,\n",
    "                    color=f'rgb({\",\".join(map(str, level_colors[level][:3]*255))})',\n",
    "                    line=dict(width=1)\n",
    "                ),\n",
    "                text=[n[:10] + '...' if len(n) > 10 else n for n in level_nodes],\n",
    "                textposition=\"top center\",\n",
    "                hovertext=hover_texts,\n",
    "                hoverinfo='text'\n",
    "            )\n",
    "            node_traces.append(node_trace)\n",
    "        \n",
    "        # Create edge trace with hover information\n",
    "        edge_x = []\n",
    "        edge_y = []\n",
    "        edge_hover_texts = []\n",
    "        \n",
    "        for edge in subgraph.edges():\n",
    "            x0, y0 = pos[edge[0]]\n",
    "            x1, y1 = pos[edge[1]]\n",
    "            edge_x.extend([x0, x1, None])\n",
    "            edge_y.extend([y0, y1, None])\n",
    "            \n",
    "            # Create hover text for edge with all edge attributes\n",
    "            edge_attrs = subgraph.edges[edge]\n",
    "            hover_text = f\"\"\"\n",
    "            From: {edge[0]}\n",
    "            To: {edge[1]}\n",
    "            Cost: {edge_attrs.get('edge_cost', 'N/A')}\n",
    "            Number: {edge_attrs.get('edge_number', 'N/A')}\n",
    "            Timestamp: {edge_attrs.get('time_stamp', 'N/A')}\n",
    "            \"\"\"\n",
    "            edge_hover_texts.extend([hover_text, hover_text, None])\n",
    "        \n",
    "        edge_trace = go.Scatter(\n",
    "            x=edge_x,\n",
    "            y=edge_y,\n",
    "            mode='lines',\n",
    "            line=dict(width=1, color='#888'),\n",
    "            hovertext=edge_hover_texts,\n",
    "            hoverinfo='text'\n",
    "        )\n",
    "        \n",
    "        # Create figure with custom hover layout\n",
    "        fig = go.Figure(\n",
    "            data=[edge_trace] + node_traces,\n",
    "            layout=go.Layout(\n",
    "                title=f'Subgraph centered on {center_node} (showing {len(subgraph)} nodes)',\n",
    "                showlegend=True,\n",
    "                hovermode='closest',\n",
    "                margin=dict(b=20, l=5, r=5, t=40),\n",
    "                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                # Customize hover label style\n",
    "                hoverlabel=dict(\n",
    "                    bgcolor=\"white\",\n",
    "                    font_size=12,\n",
    "                    font_family=\"Arial\"\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        print(f\"Total visualization time: {time.time() - start_time:.2f}s\")\n",
    "        return fig\n",
    "\n",
    "    def extract_bounded_subgraph(self, center_node: str, max_nodes: int = 1000) -> nx.DiGraph:\n",
    "        \"\"\"Extract bounded subgraph with all attributes\"\"\"\n",
    "        if center_node not in self.G:\n",
    "            return nx.DiGraph()\n",
    "            \n",
    "        subgraph_nodes = {center_node}\n",
    "        queue = [(center_node, 0)]\n",
    "        current_level = self.node_level_map[center_node]\n",
    "        level_range = 1\n",
    "        \n",
    "        while queue and len(subgraph_nodes) < max_nodes:\n",
    "            node, depth = queue.pop(0)\n",
    "            \n",
    "            for neighbor in self.G.predecessors(node):\n",
    "                if (neighbor not in subgraph_nodes and \n",
    "                    len(subgraph_nodes) < max_nodes and \n",
    "                    self.node_level_map[neighbor] >= current_level - level_range):\n",
    "                    subgraph_nodes.add(neighbor)\n",
    "                    queue.append((neighbor, depth + 1))\n",
    "                    \n",
    "            for neighbor in self.G.successors(node):\n",
    "                if (neighbor not in subgraph_nodes and \n",
    "                    len(subgraph_nodes) < max_nodes and \n",
    "                    self.node_level_map[neighbor] <= current_level + level_range):\n",
    "                    subgraph_nodes.add(neighbor)\n",
    "                    queue.append((neighbor, depth + 1))\n",
    "        \n",
    "        return self.G.subgraph(subgraph_nodes).copy()\n",
    "\n",
    "def demo_usage():\n",
    "    \"\"\"Demonstrate usage with hover information\"\"\"\n",
    "    # Initialize visualizer\n",
    "    visualizer = AttributeVisualizer()\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv('levels1mill.csv')\n",
    "    print(f\"Loaded {len(df)} rows of data\")\n",
    "    \n",
    "    # Create graph\n",
    "    start_time = time.time()\n",
    "    visualizer.bulk_create_from_df(df)\n",
    "    print(f\"Graph creation time: {time.time() - start_time:.2f}s\")\n",
    "    \n",
    "    # Create and save visualization\n",
    "    fig = visualizer.create_interactive_visualization('versyskiyo', max_nodes=10000)\n",
    "    fig.write_html(\"interactive_visualization.html\")\n",
    "    print(\"Visualization saved to 'interactive_visualization.html'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
